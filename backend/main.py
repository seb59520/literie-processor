import os
import shutil
import logging
import json
from fastapi import FastAPI, File, UploadFile, Request, Form
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware
import fitz  # PyMuPDF
import uvicorn
import tempfile
import httpx
from typing import List
from datetime import datetime
# Ajouter le r√©pertoire backend au path pour les imports (comment√© pour PyInstaller)
# import sys
# import os
# backend_dir = os.path.dirname(__file__)
# if backend_dir not in sys.path:
#     sys.path.insert(0, backend_dir)

from backend.date_utils import get_week_dates
from backend.article_utils import contient_dosseret_ou_tete, contient_fermeture_liaison, contient_surmatelas, filtrer_articles_matelas
from backend.operation_utils import mots_operation_trouves
from backend.matelas_utils import detecter_noyau_matelas
from backend.hauteur_utils import calculer_hauteur_matelas
from backend.fermete_utils import detecter_fermete_matelas
from backend.housse_utils import detecter_type_housse
from backend.matiere_housse_utils import detecter_matiere_housse
from backend.poignees_utils import detecter_poignees
from backend.dimensions_utils import detecter_dimensions
from backend.latex_naturel_referentiel import get_valeur_latex_naturel
from backend.latex_mixte7zones_referentiel import get_valeur_latex_mixte7zones
from backend.mousse_rainuree7zones_referentiel import get_valeur_mousse_rainuree7zones
from backend.select43_utils import get_select43_display_value
from backend.select43_longueur_housse_utils import get_select43_longueur_housse_value
from backend.latex_renforce_utils import get_latex_renforce_display_value
from backend.latex_renforce_longueur_utils import get_latex_renforce_longueur_housse
from backend.mousse_visco_utils import get_mousse_visco_value
from backend.mousse_visco_longueur_utils import get_mousse_visco_longueur_value
from backend.latex_naturel_longueur_housse_utils import get_latex_naturel_longueur_housse_value
from backend.latex_mixte7zones_longueur_housse_utils import get_latex_mixte7zones_longueur_housse_value
from backend.mousse_rainuree7zones_longueur_housse_utils import get_mousse_rainuree7zones_longueur_housse_value
from backend.decoupe_noyau_utils import calcul_decoupe_noyau
from backend.client_utils import extraire_donnees_client, valider_donnees_client
from backend.pre_import_utils import creer_pre_import, valider_pre_import, formater_pre_import_pour_affichage
import math
import asyncio
import sys

# Ajouter le r√©pertoire parent au path (comment√© pour PyInstaller)  
# sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from config import config
from backend.llm_provider import llm_manager

# Configuration des logs
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)
# Ajout d'un handler fichier d√©di√© pour le debug LLM - avec chemin s√©curis√©
import tempfile
from pathlib import Path

# Cr√©er un dossier de logs dans un r√©pertoire accessible
if getattr(sys, 'frozen', False):
    # Si ex√©cutable PyInstaller
    log_dir = Path.home() / "MatelasApp" / "logs"
else:
    # Si script Python normal
    log_dir = Path(__file__).parent.parent / "logs"

# Cr√©er le dossier s'il n'existe pas
log_dir.mkdir(parents=True, exist_ok=True)
log_file = log_dir / "debug_llm.log"

try:
    file_handler = logging.FileHandler(str(log_file), mode='w', encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    logger.info(f"Logs sauvegard√©s dans: {log_file}")
except Exception as e:
    # Si probl√®me d'√©criture, utiliser un fichier temporaire
    # Utiliser le r√©pertoire logs local
    if hasattr(sys, '_MEIPASS'):  # PyInstaller
        base_dir = os.path.dirname(sys.executable)
    else:
        base_dir = str(_THIS_DIR.parent)
    log_dir = os.path.join(base_dir, "logs")
    os.makedirs(log_dir, exist_ok=True)
    temp_log = Path(log_dir) / "matelas_debug.log"
    try:
        file_handler = logging.FileHandler(str(temp_log), mode='w', encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
        logger.info(f"Logs sauvegard√©s dans: {temp_log}")
    except:
        # En dernier recours, d√©sactiver les logs fichiers
        logger.info("Impossible de cr√©er le fichier de log, logs en console seulement")

app = FastAPI()

# CORS pour usage interne local uniquement
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

import pathlib
# R√©solution robuste du chemin des templates pour ex√©cution depuis racine ou backend/
_THIS_DIR = pathlib.Path(__file__).resolve().parent
_TEMPLATES_DIR = _THIS_DIR / "templates"
templates = Jinja2Templates(directory=str(_TEMPLATES_DIR))
# Utiliser un r√©pertoire d'upload local
if hasattr(sys, '_MEIPASS'):  # PyInstaller
    base_dir = os.path.dirname(sys.executable)
else:
    base_dir = _THIS_DIR.parent
temp_upload_dir = os.path.join(str(base_dir), "temp_uploads")
os.makedirs(temp_upload_dir, exist_ok=True)
UPLOAD_DIR = temp_upload_dir

@app.get("/", response_class=HTMLResponse)
def index(request: Request, result: dict = None, error: str = None):
    current_year = datetime.now().year
    logger.info(f"Acc√®s √† la page d'accueil - result: {result}, error: {error}")
    return templates.TemplateResponse("index.html", {"request": request, "result": result, "error": error, "current_year": current_year})

@app.get("/health")
def health_check():
    logger.info("Health check appel√©")
    return {"status": "ok", "message": "Application op√©rationnelle"}

@app.post("/upload", response_class=HTMLResponse)
async def upload_pdf(
    request: Request,
    file: List[UploadFile] = File(...),
    enrich_llm: str = Form("no"),
    llm_provider: str = Form("ollama"),
    openrouter_api_key: str = Form(None),
    semaine_prod: int = Form(...),
    annee_prod: int = Form(...),
    commande_client: List[str] = Form(...)
):
    logger.info(f"D√©but upload - fichiers: {[f.filename for f in file]}, enrich_llm: {enrich_llm}, llm_provider: {llm_provider}, semaine_prod: {semaine_prod}, annee_prod: {annee_prod}, commande_client: {commande_client}")
    
    results = []
    errors = []
    for idx, f in enumerate(file):
        processing_steps = {
            "progress": 0,
            "extraction": None,
            "llm": None
        }
        if not f.filename.endswith(".pdf"):
            logger.warning(f"Fichier non PDF rejet√©: {f.filename}")
            errors.append(f"Fichier non PDF: {f.filename}")
            continue
        temp_path = os.path.join(UPLOAD_DIR, f.filename)
        logger.info(f"Sauvegarde temporaire: {temp_path}")
        try:
            with open(temp_path, "wb") as buffer:
                shutil.copyfileobj(f.file, buffer)
            logger.info("Fichier sauvegard√© avec succ√®s")
        except Exception as e:
            logger.error(f"Erreur sauvegarde fichier: {e}")
            errors.append(f"Erreur sauvegarde {f.filename}: {e}")
            continue
        # Extraction du texte (I/O optimis√©e)
        try:
            logger.info("Ouverture PDF avec PyMuPDF (lecture en m√©moire)")
            with open(temp_path, "rb") as pdf_f:
                pdf_bytes = pdf_f.read()
            # Utilisation de stream pour √©viter un second acc√®s disque
            doc = fitz.open(stream=pdf_bytes, filetype="pdf")
            text = "\n".join(page.get_text() for page in doc)
            doc.close()
            logger.info(f"Extraction texte r√©ussie - {len(text)} caract√®res")
            processing_steps["extraction"] = {
                "nb_caracteres": len(text),
                "nb_mots": len(text.split()),
                "preview": text[:500] + "..." if len(text) > 500 else text
            }
            processing_steps["progress"] = 50
            # Correction : injecter un texte d'exemple si le texte est vide ou non pertinent
            if not text.strip() or not any(m in text.lower() for m in ["matelas", "sommier", "latex", "mousse", "dimensions", "fermet√©"]):
                logger.warning("Texte extrait vide ou non pertinent, injection d'un exemple pour le LLM.")
                text = "MATELAS 1 PI√àCE - MOUSSE RAINUR√âE 7 ZONES 140x190 Mme Gauche\nMATELAS 1 PI√àCE - LATEX NATUREL 160x200 Mr Droit"
        except Exception as e:
            logger.error(f"Erreur extraction PDF: {e}")
            errors.append(f"Erreur extraction {f.filename}: {e}")
            continue
        # LLM (optionnel)
        llm_result = None
        if enrich_llm == "yes":
            if llm_provider == "ollama":
                try:
                    logger.info("Appel au LLM (Ollama)")
                    # D√©porter l'appel sync dans un thread pour ne pas bloquer
                    loop = asyncio.get_event_loop()
                    llm_result = await loop.run_in_executor(None, lambda: asyncio.run(call_llm(text)))
                    logger.info(f"LLM appel√© avec succ√®s - r√©ponse: {llm_result[:100]}...")
                    try:
                        llm_data = json.loads(llm_result)
                        processing_steps["llm"] = {
                            "model": "gpt-oss:20b",
                            "articles": {
                                "articles": len(llm_data.get("articles", [])),
                                "societe": 1 if llm_data.get("societe") else 0,
                                "client": 1 if llm_data.get("client") else 0,
                                "commande": 1 if llm_data.get("commande") else 0,
                                "paiement": 1 if llm_data.get("paiement") else 0
                            },
                            "raw_result": llm_result
                        }
                    except:
                                            processing_steps["llm"] = {
                        "model": "gpt-oss:20b",
                        "raw_result": llm_result
                    }
                    processing_steps["progress"] = 100
                except Exception as e:
                    logger.error(f"Erreur LLM: {e}")
                    llm_result = f"Erreur LLM: {e}"
                    processing_steps["llm"] = {
                        "model": "gpt-oss:20b",
                        "error": str(e)
                    }
            elif llm_provider == "openrouter":
                try:
                    if not openrouter_api_key:
                        raise Exception("Cl√© API OpenRouter manquante")
                    logger.info("Appel √† OpenRouter avec GPT-4-Turbo")
                    # D√©porter l'appel sync dans un thread pour ne pas bloquer
                    loop = asyncio.get_event_loop()
                    llm_result = await loop.run_in_executor(None, lambda: asyncio.run(call_llm(text)))
                    logger.info(f"OpenRouter appel√© avec succ√®s - r√©ponse: {llm_result[:100]}...")
                    try:
                        llm_data = json.loads(llm_result)
                        processing_steps["llm"] = {
                            "model": "openai/gpt-4-turbo",
                            "articles": {
                                "articles": len(llm_data.get("articles", [])),
                                "societe": 1 if llm_data.get("societe") else 0,
                                "client": 1 if llm_data.get("client") else 0,
                                "commande": 1 if llm_data.get("commande") else 0,
                                "paiement": 1 if llm_data.get("paiement") else 0
                            },
                            "raw_result": llm_result
                        }
                    except json.JSONDecodeError as json_err:
                        logger.warning(f"Erreur parsing JSON OpenRouter: {json_err}")
                        processing_steps["llm"] = {
                            "model": "openai/gpt-4-turbo",
                            "raw_result": llm_result,
                            "json_error": str(json_err)
                        }
                    processing_steps["progress"] = 100
                except Exception as e:
                    logger.error(f"Erreur OpenRouter: {e}")
                    llm_result = f"Erreur OpenRouter: {e}"
                    processing_steps["llm"] = {
                        "model": "openai/gpt-4-turbo",
                        "error": str(e)
                    }
        else:
            processing_steps["progress"] = 100
        # Nettoyage du fichier temporaire
        try:
            os.remove(temp_path)
            logger.info("Fichier temporaire supprim√©")
        except Exception as e:
            logger.warning(f"Erreur suppression fichier temporaire: {e}")
        # V√©rification DOSSERET/TETE apr√®s LLM
        contient_dosseret_tete = False
        articles_llm = []
        mots_operation_list = []
        noyaux_matelas = []
        donnees_client = {}
        try:
            logger.info(f"D√©but traitement LLM pour {f.filename}")
            if llm_result and llm_result.strip():
                logger.info(f"LLM result trouv√© pour {f.filename}, longueur: {len(llm_result)}")
                logger.info(f"LLM result brut pour {f.filename}: {llm_result[:500]}...")
                
                # Nettoyer et parser le JSON
                cleaned_llm_result = clean_and_parse_json(llm_result)
                logger.info(f"LLM result nettoy√© pour {f.filename}, longueur: {len(cleaned_llm_result)}")
                logger.info(f"LLM result nettoy√© pour {f.filename}: {cleaned_llm_result[:500]}...")
                
                if cleaned_llm_result.strip():
                    try:
                        llm_data = json.loads(cleaned_llm_result)
                        logger.info(f"JSON pars√© avec succ√®s pour {f.filename}")
                        if not isinstance(llm_data, dict):
                            logger.warning(f"LLM result n'est pas un dictionnaire pour {f.filename}: {type(llm_data)}")
                            llm_data = {}
                        else:
                            logger.info(f"llm_data est un dictionnaire valide pour {f.filename}")
                            # Extraction des donn√©es client
                            donnees_client = extraire_donnees_client(llm_data)
                            logger.info(f"Donn√©es client extraites pour {f.filename}: {donnees_client}")
                    except json.JSONDecodeError as json_err:
                        logger.error(f"Erreur parsing JSON pour {f.filename}: {json_err}")
                        logger.error(f"Contenu qui cause l'erreur: {cleaned_llm_result}")
                        llm_data = {}
                else:
                    logger.warning(f"LLM result vide apr√®s nettoyage pour {f.filename}")
                    llm_data = {}
            else:
                logger.warning(f"Pas de r√©sultat LLM pour {f.filename}")
                llm_data = {}
            
            # Traitement des donn√©es LLM (que ce soit avec ou sans LLM)
            logger.info(f"Traitement des donn√©es LLM pour {f.filename}")
            logger.info(f"Type de llm_data: {type(llm_data)}")
            logger.info(f"Contenu de llm_data: {llm_data}")
            logger.info(f"Cl√©s dans llm_data pour {f.filename}: {list(llm_data.keys())}")
            if 'articles' in llm_data and llm_data['articles']:
                logger.info(f"Premier article: {llm_data['articles'][0]}")
            else:
                logger.info(f"Aucun article trouv√© dans llm_data['articles']")
            # On cherche dans tous les articles potentiels
            articles_llm = []
            matelas_articles = []
            conditions_paiement = []
            mots_operation_list = []  # Initialisation ici
            for key in llm_data:
                logger.info(f"Traitement de la cl√© '{key}' pour {f.filename}")
                if isinstance(llm_data[key], list):
                    articles_llm.extend(llm_data[key])
                    logger.info(f"Articles ajout√©s pour {f.filename}, total: {len(articles_llm)}")
                    if key.lower() == "articles":
                        logger.info(f"Traitement des articles pour {f.filename}")
                        # Appliquer le filtrage pour exclure les PROT√àGE MATELAS
                        articles_filtres = filtrer_articles_matelas(llm_data[key])
                        logger.info(f"Articles apr√®s filtrage pour {f.filename}: {len(articles_filtres)} (avant: {len(llm_data[key])})")
                        
                        for article in articles_filtres:
                            description = article.get('description', '').upper()
                            logger.info(f"Article description pour {f.filename}: {description[:50]}...")
                            if description.startswith('MATELAS'):
                                logger.info(f"Matelas trouv√© pour {f.filename}: {description[:50]}...")
                                logger.info(f"Article matelas complet: {article}")
                                matelas_articles.append(article)
                elif key == "paiement" and isinstance(llm_data[key], dict):
                    # Ajouter les conditions de paiement pour la recherche des mots op√©rationnels
                    conditions_paiement.append(llm_data[key])
                    logger.info(f"Conditions paiement ajout√©es pour {f.filename}")
            logger.info(f"DEBUG articles_llm pour {f.filename}: {articles_llm}")
            logger.info(f"DEBUG matelas_articles pour {f.filename}: {matelas_articles}")
            logger.info(f"DEBUG conditions_paiement pour {f.filename}: {conditions_paiement}")
            contient_dosseret_tete = contient_dosseret_ou_tete(articles_llm)
            # Rechercher les mots op√©rationnels dans les articles ET dans le texte complet du PDF
            mots_operation_list = mots_operation_trouves(articles_llm + conditions_paiement, text)
            logger.info(f"DEBUG mots_operation_trouves pour {f.filename}: {mots_operation_list}")
            noyaux_matelas = detecter_noyau_matelas(matelas_articles)
            logger.info(f"DEBUG noyaux_matelas pour {f.filename}: {noyaux_matelas}")
        except Exception as e:
            logger.warning(f"Erreur d√©tection dosseret/tete, mots op√©ration ou noyau matelas: {e}")
            contient_dosseret_tete = False
            mots_operation_list = []
            noyaux_matelas = []
        # Apr√®s extraction des articles_llm (avant la boucle sur les matelas)
        fermeture_liaison = contient_fermeture_liaison(articles_llm)
        surmatelas = contient_surmatelas(articles_llm)
        # Calcul date pour chaque fichier
        semaine_annee = f"{semaine_prod}_{annee_prod}"
        lundi, vendredi = get_week_dates(semaine_prod, annee_prod)
        cc_val = commande_client[idx] if idx < len(commande_client) else ""
        
        # Cr√©er une configuration pour chaque matelas trouv√©
        configurations_matelas = []
        config_index = 1
        # On r√©cup√®re la liste des articles LLM d'origine pour avoir titre_cote
        articles_llm_origin = llm_data.get('articles', []) if isinstance(llm_data, dict) else []
        
        # Ne traiter que les articles qui ont un noyau d√©tect√© (exclut automatiquement les prot√®ge-matelas)
        for noyau_info in noyaux_matelas:
            idx = noyau_info["index"] - 1  # index est 1-based, on le convertit en 0-based
            if idx >= len(matelas_articles):
                continue
            article = matelas_articles[idx]
            config = article.copy()
            
            # Ajout du traitement du champ information
            info = article.get("information", "")
            config["information"] = info
            
            config["matelas_index"] = config_index
            config["commande_client"] = cc_val
            config["semaine_annee"] = semaine_annee
            config["lundi"] = lundi
            config["vendredi"] = vendredi
            
            # Assigner le noyau d√©tect√©
            config["noyau"] = noyau_info["noyau"]
            
            # DEBUG: Log de l'article en cours de traitement
            logger.info(f"MAIN DEBUG: Traitement article matelas {config_index}")
            logger.info(f"MAIN DEBUG: article keys: {list(article.keys())}")
            logger.info(f"MAIN DEBUG: titre_cote in article: {'titre_cote' in article}")
            if 'description' in article:
                logger.info(f"MAIN DEBUG: description: '{article['description'][:80]}...'")
                
            # Copie du champ titre_cote depuis l'article matelas actuel (d√©j√† filtr√©)
            if "titre_cote" in article and article["titre_cote"]:
                config["titre_cote"] = article["titre_cote"]
                logger.info(f"MAIN DEBUG: titre_cote copi√© depuis article: '{config['titre_cote']}'")
            else:
                logger.info(f"MAIN DEBUG: titre_cote absent ou vide dans article, fallback activ√©")
                # Fallback: chercher dans articles_llm_origin par matching de description
                config["titre_cote"] = ""
                article_desc = article.get("description", "")
                logger.info(f"MAIN DEBUG: description pour matching: '{article_desc[:50]}...'")
                
                for llm_art in articles_llm_origin:
                    if (llm_art.get("type") == "matelas" and 
                        llm_art.get("description", "") == article_desc and
                        llm_art.get("titre_cote", "")):
                        config["titre_cote"] = llm_art["titre_cote"]
                        logger.info(f"MAIN DEBUG: titre_cote trouv√© par matching: '{config['titre_cote']}'")
                        break
                
                # Fallback final: extraction directe depuis la description
                if not config["titre_cote"] and article_desc:
                    logger.info(f"MAIN DEBUG: Fallback final - extraction directe depuis: '{article_desc[-60:]}'")  
                    import re
                    match = re.search(r'[-\s]+(Mr|MR|Mme|MME)\s*$', article_desc.strip())
                    if match:
                        config["titre_cote"] = match.group(1).upper()
                        logger.info(f"FALLBACK SUCCESS: Extraction directe titre_cote: '{config['titre_cote']}'")
                    else:
                        logger.info(f"FALLBACK FAIL: Aucun MR/MME trouv√© dans la description")
                else:
                    logger.info(f"MAIN DEBUG: Pas de fallback final (config titre_cote: '{config.get('titre_cote', 'N/A')}', article_desc: {bool(article_desc)})")
                
            # Extraction du titre simple (Mr ou Mme) si pr√©sent
            if config.get("titre_cote"):
                import re
                match = re.search(r"(Mr|Mme|MR|MME)", config["titre_cote"])
                config["titre_cote_simple"] = match.group(1) if match else ""
            else:
                config["titre_cote_simple"] = ""
            configurations_matelas.append(config)
            config_index += 1
        # Correction 1 : injecter le texte extrait dans donnees_client pour la d√©tection mise √† disposition
        donnees_client["devis_text"] = text
        # Correction 2 : d√©tection robuste du mode de mise √† disposition sur tout le texte ET sur les descriptions d'articles
        from backend.pre_import_utils import detect_mode_mise_a_disposition, normalize_text
        texte_global = text
        descriptions = "\n".join([a.get("description", "") for a in articles_llm_origin])
        logger.info(f"Texte utilis√© pour la d√©tection mise √† disposition (global): {texte_global[:200]}")
        logger.info(f"Descriptions utilis√©es pour la d√©tection mise √† disposition: {descriptions[:200]}")
        mode_global = detect_mode_mise_a_disposition(texte_global)
        mode_desc = detect_mode_mise_a_disposition(descriptions)
        # On priorise la valeur du LLM si elle existe, sinon on met "X" ou ""
        mode_llm = llm_data.get("mode_mise_a_disposition", {}) if isinstance(llm_data, dict) else {}
        mode_final = {}
        for k in ["emporte_client_C57", "fourgon_C58", "transporteur_C59"]:
            if mode_llm.get(k, "").strip():
                mode_final[k] = mode_llm[k]
            elif mode_global.get(k) == "X" or mode_desc.get(k) == "X":
                mode_final[k] = "X"
            else:
                mode_final[k] = ""
        donnees_client["mode_mise_a_disposition"] = mode_final
        # Appel au pr√©-import
        pre_import_data = creer_pre_import(configurations_matelas, donnees_client, contient_dosseret_tete, mots_operation_list, fermeture_liaison)
        logger.info(f"Pr√©-import cr√©√© avec succ√®s: {len(pre_import_data)} √©l√©ments")
        
        # Validation du pr√©-import
        if valider_pre_import(pre_import_data):
            logger.info("Pr√©-import valid√© avec succ√®s")
        else:
            logger.warning("Pr√©-import non valide")
        
        # === AJOUT EXPORT EXCEL ===
        try:
            # Import stable avec pr√©fixe backend
            from backend.excel_import_utils import ExcelMatelasImporter
            semaine = str(semaine_prod).zfill(2)
            annee = str(annee_prod)
            semaine_excel = f"S{semaine}"
            # Utiliser l'ann√©e compl√®te pour le nommage
            id_fichier = annee
            importer = ExcelMatelasImporter()
            fichiers_excel = importer.import_configurations(pre_import_data, semaine_excel, id_fichier)
            logger.info(f"Export Excel termin√©: {fichiers_excel}")
        except Exception as e:
            logger.error(f"Erreur lors de l'export Excel: {e}")
        # === FIN AJOUT EXPORT EXCEL ===
                
        # Garder aussi l'ancienne structure pour compatibilit√©
        calcul_date = {
            "semaine_annee": semaine_annee,
            "lundi": lundi,
            "vendredi": vendredi,
            "commande_client": cc_val
        }
        result = {
            "filename": f.filename,
            "extraction_stats": processing_steps["extraction"] if processing_steps["extraction"] else {},
            "texte_extrait": text if 'text' in locals() else "",
            "llm_result": llm_result if 'llm_result' in locals() else None,
            "processing_steps": processing_steps,
            "calcul_date": calcul_date,
            "configurations_matelas": configurations_matelas,
            "contient_dosseret_ou_tete": contient_dosseret_tete,
            "mots_operation_trouves": mots_operation_list,
            "noyaux_matelas": noyaux_matelas,
            "fermeture_liaison": fermeture_liaison,
            "surmatelas": surmatelas,
            "donnees_client": donnees_client,
            "pre_import": pre_import_data
        }
        results.append(result)
    # Affichage des erreurs √©ventuelles
    error_msg = "\n".join(errors) if errors else None
    return templates.TemplateResponse("index.html", {"request": request, "results": results, "error": error_msg, "semaine_prod": semaine_prod, "annee_prod": annee_prod, "commande_client": commande_client})

def clean_and_parse_json(raw_text: str) -> str:
    """Nettoie et parse le JSON retourn√© par le LLM"""
    if not raw_text or not raw_text.strip():
        logger.warning("Texte JSON vide ou None")
        return ""
    
    try:
        # Supprime les caract√®res Unicode probl√©matiques
        cleaned_text = raw_text.encode('utf-8', errors='ignore').decode('utf-8')
        
        # Essaie de parser directement
        json.loads(cleaned_text)
        return cleaned_text
    except json.JSONDecodeError as e:
        logger.warning(f"Premier essai de parsing JSON √©chou√©: {e}")
        
        # Si √ßa ne marche pas, on essaie de nettoyer plus agressivement
        try:
            # Supprime les caract√®res non-ASCII
            cleaned_text = ''.join(char for char in raw_text if ord(char) < 128)
            json.loads(cleaned_text)
            return cleaned_text
        except json.JSONDecodeError as e2:
            logger.warning(f"Deuxi√®me essai de parsing JSON √©chou√©: {e2}")
            
            # Essai de nettoyage des balises markdown
            try:
                # Supprime les balises ```json et ```
                cleaned_text = raw_text.replace('```json', '').replace('```', '').strip()
                json.loads(cleaned_text)
                return cleaned_text
            except json.JSONDecodeError as e3:
                logger.warning(f"Troisi√®me essai de parsing JSON √©chou√©: {e3}")
                
                # Essai de nettoyage plus agressif des balises markdown
                try:
                    # Supprime toutes les balises markdown possibles
                    cleaned_text = raw_text
                    for marker in ['```json', '```JSON', '```', '`']:
                        cleaned_text = cleaned_text.replace(marker, '')
                    cleaned_text = cleaned_text.strip()
                    json.loads(cleaned_text)
                    return cleaned_text
                except json.JSONDecodeError as e4:
                    logger.warning(f"Quatri√®me essai de parsing JSON √©chou√©: {e4}")
                    
                    # En dernier recours, on retourne le texte original
                    logger.error(f"Impossible de parser le JSON: {raw_text[:200]}...")
                    return raw_text

def decode_unicode_strings(obj):
    """D√©code r√©cursivement les cha√Ænes Unicode dans un objet JSON"""
    if isinstance(obj, dict):
        return {key: decode_unicode_strings(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [decode_unicode_strings(item) for item in obj]
    elif isinstance(obj, str):
        try:
            # Essaie de d√©coder les s√©quences Unicode
            return obj.encode('latin-1').decode('unicode_escape')
        except:
            return obj
    else:
        return obj

async def call_llm(text: str, file_name: str = "unknown", file_size: int = 0, session_id: str = None):
    """
    Appelle le LLM configur√© par l'utilisateur avec tracking des co√ªts
    """
    try:
        # Importer les modules de tracking
        from backend.llm_provider import llm_manager
        from backend.secure_storage import secure_storage
        from backend.cost_tracker import cost_tracker
        
        current_provider = config.get_current_llm_provider()
        
        # Configuration du provider avec le nouveau syst√®me
        if current_provider == "ollama":
            api_key = None
        else:
            # Essayer d'abord le stockage s√©curis√©, puis fallback sur config
            api_key = secure_storage.load_api_key(current_provider)
            if not api_key:
                api_key = config.get_llm_api_key(current_provider)
            
            if not api_key:
                logger.error(f"Aucune cl√© API configur√©e pour {current_provider}")
                return f"Erreur: Cl√© API manquante pour {current_provider}"
        
        # Configurer le LLM manager
        llm_manager.set_provider(current_provider, api_key)
        
        # Prompt unifi√© pour tous les providers
        prompt = f"""
Tu es un assistant d'extraction sp√©cialis√© pour des devis de literie. Analyse le texte ci-dessous et g√©n√®re uniquement un JSON structur√© selon le format exact suivant.

TEXTE √Ä ANALYSER :
{text}

R√àGLES D'EXTRACTION STRICTES :

1. STRUCTURE JSON OBLIGATOIRE :
{{
  "societe": {{
    "nom": "nom de l'entreprise",
    "capital": "capital social",
    "adresse": "adresse compl√®te",
    "telephone": "num√©ro de t√©l√©phone",
    "email": "adresse email",
    "siret": "num√©ro SIRET",
    "APE": "code APE",
    "CEE": "num√©ro CEE",
    "banque": "nom de la banque",
    "IBAN": "num√©ro IBAN"
  }},
  "client": {{
    "nom": "nom du client",
    "adresse": "adresse du client",
    "code_client": "code client"
  }},
  "commande": {{
    "numero": "num√©ro de commande",
    "date": "date de commande",
    "date_validite": "date de validit√©",
    "commercial": "nom du commercial",
    "origine": "origine de la commande"
  }},
  "mode_mise_a_disposition": {{
    "emporte_client_C57": "texte si enl√®vement client",
    "fourgon_C58": "texte si livraison fourgon",
    "transporteur_C59": "texte si transporteur"
  }},
  "articles": [
    {{
      "type": "matelas|sommier|accessoire|t√™te de lit|pieds|remise",
      "description": "description compl√®te de l'article",
      "titre_cote": "OBLIGATOIRE: Chercher '- MME', '- MR', '- Mr', '- Mme' √† la fin des descriptions de matelas (ex: 'MATELAS... 20 - MME' ‚Üí 'MME', 'LATEX 20 - MR' ‚Üí 'MR'). Si pas trouv√©, laisser vide.",
      "information": "en-t√™te comme '1/ CHAMBRE XYZ' si pr√©sent",
      "quantite": nombre,
      "dimensions": "format LxlxH",
      "noyau": "type de noyau pour matelas",
      "fermete": "niveau de fermet√©",
      "housse": "type de housse",
      "matiere_housse": "mat√©riau de la housse",
      "autres_caracteristiques": {{
        "caracteristique1": "valeur1",
        "caracteristique2": "valeur2"
      }}
    }}
  ],
  "paiement": {{
    "conditions": "conditions de paiement",
    "port_ht": montant_ht_port,
    "base_ht": montant_ht_total,
    "taux_tva": pourcentage_tva,
    "total_ttc": montant_ttc,
    "acompte": montant_acompte,
    "net_a_payer": montant_final
  }}
}}

2. R√àGLES SP√âCIFIQUES :
- Pour chaque article, extraire TOUS les champs disponibles
- Le champ "autres_caracteristiques" doit contenir les sp√©cificit√©s non standard
- Les remises sont des articles de type "remise" avec montant dans autres_caracteristiques
- Les dimensions doivent √™tre au format "LxlxH" (ex: "159x199x19")
- Les montants doivent √™tre des nombres (pas de texte)
- Si une information est absente : null pour les nombres, "" pour les textes
- IMPORTANT titre_cote: Pour chaque matelas, chercher √† la fin de la description s'il y a "- MME", "- MR", "- Mr", ou "- Mme" et extraire seulement la partie apr√®s le tiret (MME, MR, Mr, Mme). Exemple: "MATELAS LATEX 79/198/20 - MME" ‚Üí titre_cote: "MME"

3. EXEMPLE DE R√âF√âRENCE :
{{
  "societe": {{
    "nom": "SAS Literie Westelynck",
    "capital": "23 100 Euros",
    "adresse": "525 RD 642 - 59190 BORRE",
    "telephone": "03.28.48.04.19",
    "email": "contact@lwest.fr",
    "siret": "429 352 891 00015",
    "APE": "3103Z",
    "CEE": "FR50 429 352 891",
    "banque": "Cr√©dit Agricole d'Hazebrouck",
    "IBAN": "FR76 1670 6050 1650 4613 2602 341"
  }},
  "client": {{
    "nom": "Mr et Me LAGADEC HELENE",
    "adresse": "25 RUE DE L'√âGLISE, 59670 BAVINCHOVE",
    "code_client": "LAGAHEBAV"
  }},
  "commande": {{
    "numero": "CM00009581",
    "date": "19/07/2025",
    "date_validite": "",
    "commercial": "P. ALINE",
    "origine": "COMMANDE"
  }},
  "mode_mise_a_disposition": {{
    "emporte_client_C57": "ENL√àVEMENT PAR VOS SOINS",
    "fourgon_C58": "",
    "transporteur_C59": ""
  }},
  "articles": [
    {{
      "type": "matelas",
      "description": "MATELAS 1 PI√àCE - LATEX PERFOR√â 7 ZONES M√âDIUM - HOUSSE TENCEL 79/198/20 - MME",
      "titre_cote": "MME",
      "information": "",
      "quantite": 2,
      "dimensions": "79x198x20",
      "noyau": "MOUSSE RAINUR√âE 7 ZONES",
      "fermete": "M√âDIUM",
      "housse": "MATELASS√âE",
      "matiere_housse": "TENCEL",
      "autres_caracteristiques": {{
        "poign√©es": "oui",
        "lavable": "40¬∞"
      }}
    }}
  ],
  "paiement": {{
    "conditions": "ACOMPTE DE 667 ‚Ç¨ EN CB LA COMMANDE ET SOLDE DE 1 500 ‚Ç¨ √Ä L'ENL√àVEMENT",
    "port_ht": 0.00,
    "base_ht": 1774.21,
    "taux_tva": 20.00,
    "total_ttc": 2167.00,
    "acompte": 667.00,
    "net_a_payer": 1500.00
  }}
}}

R√©ponds UNIQUEMENT avec un JSON valide selon cette structure exacte.
"""
        logger.info(f"Prompt envoy√© au LLM ({current_provider}) :\n{prompt}")
        logger.info(f"Appel LLM avec provider: {current_provider}")
        
        # Appel avec tracking des co√ªts
        result = llm_manager.call_llm(
            prompt, 
            file_name=file_name,
            file_size=file_size,
            session_id=session_id,
            temperature=0.1, 
            max_tokens=2000
        )
        
        if result["success"]:
            # Log des informations de co√ªt si disponibles
            if 'cost_info' in result:
                cost_info = result['cost_info']
                logger.info(f"üí∞ Co√ªt appel LLM: ${cost_info['total_cost']:.6f} "
                           f"({result['usage'].get('prompt_tokens', 0)} prompt + "
                           f"{result['usage'].get('completion_tokens', 0)} completion tokens)")
            
            return result["content"]
        else:
            logger.error(f"Erreur LLM {current_provider}: {result.get('error', 'Erreur inconnue')}")
            return f"Erreur LLM {current_provider}: {result.get('error', 'Erreur inconnue')}"
    except Exception as e:
        logger.error(f"Erreur lors de l'appel LLM: {e}")
        return f"Erreur lors de l'appel LLM: {str(e)}"

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000) 
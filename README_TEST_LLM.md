# ğŸ§ª Application de Test LLM - MatelasApp

## ğŸ“‹ Description

Application graphique pour tester les prompts LLM, providers et modÃ¨les utilisÃ©s dans MatelasApp. Permet de valider et optimiser les prompts avant leur dÃ©ploiement en production.

## ğŸš€ Lancement

### Windows
```bash
lancer_test_llm.bat
```

### Linux/Mac
```bash
chmod +x lancer_test_llm.sh
./lancer_test_llm.sh
```

### Python direct
```bash
python lancer_test_llm.py
```

## ğŸ¯ FonctionnalitÃ©s

### ğŸ”§ Configuration des Providers
- **Ollama** : ModÃ¨les locaux avec gestion avancÃ©e
  - **DÃ©tection automatique** : Liste automatique des modÃ¨les installÃ©s
  - **Ajout de modÃ¨les** : Bouton â• pour ajouter de nouveaux modÃ¨les
  - **RafraÃ®chissement** : Bouton ğŸ”„ pour actualiser la liste
  - **TÃ©lÃ©chargement** : TÃ©lÃ©chargement automatique des modÃ¨les
- **OpenRouter** : AccÃ¨s Ã  GPT-4, Claude, etc.
- **OpenAI** : API OpenAI directe
- **Anthropic** : API Claude directe

### ğŸ“ Gestion des Prompts
- **Restaurer le prompt actuel** : RÃ©cupÃ¨re automatiquement le prompt depuis `main.py`
- **Sauvegarder/Loader** : Gestion des prompts personnalisÃ©s
- **Ã‰dition en temps rÃ©el** : Modification du prompt pour les tests

### ğŸ“„ Gestion des Textes de Test
- **Chargement PDF** : Extraction automatique du texte
- **Chargement fichiers texte** : Support des formats .txt
- **Ã‰dition directe** : Saisie manuelle du texte de test

### ğŸ§ª Tests LLM
- **ParamÃ¨tres configurables** : TempÃ©rature, max_tokens
- **Explications de tempÃ©rature** : Guide interactif pour comprendre l'impact
- **Tests asynchrones** : Interface non-bloquante
- **RÃ©sultats dÃ©taillÃ©s** : Affichage brut + JSON parsÃ©
- **Gestion d'erreurs** : Messages d'erreur clairs

### ğŸŒ¡ï¸ ParamÃ¨tres LLM

#### TempÃ©rature
La tempÃ©rature contrÃ´le la crÃ©ativitÃ© et la prÃ©visibilitÃ© des rÃ©ponses :

- **0.0** : DÃ©terministe - RÃ©ponses cohÃ©rentes et prÃ©visibles
- **0.1-0.3** : Faible crÃ©ativitÃ© - RÃ©ponses structurÃ©es et prÃ©cises
- **0.4-0.7** : CrÃ©ativitÃ© modÃ©rÃ©e - Ã‰quilibrÃ© entre prÃ©cision et crÃ©ativitÃ©
- **0.8-1.0** : CrÃ©ativitÃ© Ã©levÃ©e - RÃ©ponses variÃ©es et originales
- **1.1-2.0** : TrÃ¨s crÃ©atif - RÃ©ponses trÃ¨s variÃ©es et imprÃ©visibles

#### Max Tokens
Nombre maximum de tokens dans la rÃ©ponse gÃ©nÃ©rÃ©e (100-4000).

### ğŸ“Š Historique et Analyse
- **Historique des tests** : Sauvegarde de tous les tests
- **Export JSON** : Sauvegarde des rÃ©sultats
- **Comparaison** : Visualisation des diffÃ©rences entre tests

## ğŸ–¥ï¸ Interface

### Panneau Gauche - Configuration
1. **Configuration Provider**
   - SÃ©lection du provider (Ollama, OpenRouter, etc.)
   - Saisie de la clÃ© API
   - Choix du modÃ¨le
   - ParamÃ¨tres (tempÃ©rature, max_tokens)

2. **Gestion du Prompt**
   - Bouton "Restaurer Prompt Actuel"
   - Sauvegarde/Chargement de prompts
   - Ã‰diteur de prompt avec coloration syntaxique

3. **Texte de Test**
   - Chargement PDF/TXT
   - Ã‰diteur de texte
   - Bouton "Lancer Test LLM"

### Panneau Droit - RÃ©sultats
1. **Onglet RÃ©sultats**
   - Informations du test (provider, modÃ¨le, paramÃ¨tres)
   - RÃ©sultat brut du LLM
   - JSON parsÃ© et formatÃ©

2. **Onglet Historique**
   - Tableau des tests effectuÃ©s
   - Actions (voir, exporter)
   - Gestion de l'historique

3. **Onglet Configuration**
   - Ã‰tat de la configuration actuelle
   - Test de configuration
   - ClÃ©s API configurÃ©es

## ğŸ”‘ Configuration des ClÃ©s API

L'application utilise automatiquement les clÃ©s API configurÃ©es dans MatelasApp :

### Synchronisation Automatique
- **Chargement automatique** : Les clÃ©s API sont automatiquement chargÃ©es au dÃ©marrage
- **Synchronisation par provider** : Les clÃ©s se synchronisent automatiquement lors du changement de provider
- **Bouton de synchronisation** : Cliquez sur le bouton ğŸ”„ Ã  cÃ´tÃ© du champ "ClÃ© API" pour forcer la synchronisation
- **Messages informatifs** : La barre de statut indique l'Ã©tat de la synchronisation

### Configuration des Providers

#### Ollama
Aucune clÃ© requise, mais Ollama doit Ãªtre installÃ© et en cours d'exÃ©cution.

**Gestion des modÃ¨les :**
1. **DÃ©tection automatique** : Les modÃ¨les installÃ©s sont automatiquement listÃ©s
2. **Ajout de modÃ¨les** : Cliquez sur â• pour ajouter un nouveau modÃ¨le
3. **TÃ©lÃ©chargement** : L'application peut tÃ©lÃ©charger automatiquement les modÃ¨les
4. **RafraÃ®chissement** : Cliquez sur ğŸ”„ pour actualiser la liste des modÃ¨les

**ModÃ¨les populaires :**
- `mistral:latest` - ModÃ¨le rapide et efficace
- `llama2:latest` - ModÃ¨le Ã©quilibrÃ©
- `codellama:latest` - SpÃ©cialisÃ© en code
- `llama2:7b` - Version lÃ©gÃ¨re
- `llama2:13b` - Version plus puissante

#### OpenRouter
1. CrÃ©er un compte sur [OpenRouter](https://openrouter.ai)
2. GÃ©nÃ©rer une clÃ© API
3. Configurer dans MatelasApp (Menu RÃ©glages â†’ Gestion des clÃ©s API)

#### OpenAI
1. CrÃ©er un compte sur [OpenAI](https://openai.com)
2. GÃ©nÃ©rer une clÃ© API
3. Configurer dans MatelasApp (Menu RÃ©glages â†’ Gestion des clÃ©s API)

#### Anthropic
1. CrÃ©er un compte sur [Anthropic](https://anthropic.com)
2. GÃ©nÃ©rer une clÃ© API
3. Configurer dans MatelasApp (Menu RÃ©glages â†’ Gestion des clÃ©s API)

## ğŸ“ Utilisation

### 1. Test Rapide
1. Lancer l'application
2. Le prompt actuel est automatiquement chargÃ©
3. Entrer un texte de test simple
4. Cliquer sur "Lancer Test LLM"

### 2. Test avec PDF
1. Cliquer sur "Charger PDF"
2. SÃ©lectionner un devis PDF
3. Le texte est automatiquement extrait
4. Lancer le test

### 3. Optimisation de Prompt
1. Modifier le prompt dans l'Ã©diteur
2. Tester avec diffÃ©rents textes
3. Comparer les rÃ©sultats
4. Sauvegarder le meilleur prompt

### 4. Test de Configuration
1. Aller dans l'onglet "Configuration"
2. Cliquer sur "Tester Configuration"
3. VÃ©rifier que tout fonctionne

## ğŸ› DÃ©pannage

### Erreur "PyQt non trouvÃ©"
```bash
pip install PyQt6
# ou
pip install PyQt5
```

### Erreur "Modules backend"
- VÃ©rifier d'Ãªtre dans le rÃ©pertoire racine du projet
- VÃ©rifier que `config.py` et `backend/` existent

### Erreur "ClÃ© API manquante"
- Configurer la clÃ© API dans l'application
- VÃ©rifier que la clÃ© est valide

### Erreur "Provider non configurÃ©"
- VÃ©rifier que le provider est correctement configurÃ©
- Tester la configuration dans l'onglet dÃ©diÃ©

## ğŸ“ Fichiers

- `test_llm_prompt.py` : Application principale
- `lancer_test_llm.py` : Script de lancement Python
- `lancer_test_llm.bat` : Lanceur Windows
- `lancer_test_llm.sh` : Lanceur Linux/Mac
- `README_TEST_LLM.md` : Cette documentation

## ğŸ”„ IntÃ©gration avec MatelasApp

L'application utilise les mÃªmes modules que MatelasApp :
- `config.py` : Configuration des providers
- `backend/llm_provider.py` : Gestion des appels LLM
- `backend/main.py` : RÃ©cupÃ©ration du prompt actuel

Les modifications de prompt testÃ©es peuvent Ãªtre directement appliquÃ©es Ã  `main.py`.

## ğŸ‰ Avantages

1. **Tests rapides** : Validation immÃ©diate des prompts
2. **Interface intuitive** : Pas besoin de ligne de commande
3. **Historique complet** : TraÃ§abilitÃ© des tests
4. **Multi-providers** : Test de tous les providers configurÃ©s
5. **IntÃ©gration native** : Utilise la mÃªme configuration que MatelasApp 
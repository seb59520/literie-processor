#!/usr/bin/env python3
"""
Script pour forcer la configuration Ollama avec gpt-oss:20b
et Ã©viter le fallback automatique sur mistral:latest
"""

import json
import os
import shutil

def forcer_configuration_gpt_oss():
    """Force la configuration Ollama avec gpt-oss:20b"""
    
    print("ğŸš€ FORÃ‡AGE DE LA CONFIGURATION OLLAMA AVEC GPT-OSS:20B")
    print("=" * 60)
    
    # 1. VÃ©rifier le fichier de configuration actuel
    print("\nğŸ“ 1. VÃ©rification de la configuration actuelle:")
    
    config_file = 'matelas_config.json'
    if os.path.exists(config_file):
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            print(f"   âœ… {config_file} trouvÃ© et lu")
        except Exception as e:
            print(f"   âŒ Erreur lecture {config_file}: {e}")
            config = {}
    else:
        print(f"   âŒ {config_file} non trouvÃ©, crÃ©ation d'une nouvelle configuration")
        config = {}
    
    # 2. Sauvegarder l'ancienne configuration
    print("\nğŸ’¾ 2. Sauvegarde de l'ancienne configuration:")
    
    backup_file = f"{config_file}.backup.{int(os.path.getmtime(config_file) if os.path.exists(config_file) else 0)}"
    if os.path.exists(config_file):
        shutil.copy2(config_file, backup_file)
        print(f"   âœ… Sauvegarde crÃ©Ã©e: {backup_file}")
    else:
        print("   â„¹ï¸ Pas de sauvegarde nÃ©cessaire (nouveau fichier)")
    
    # 3. Forcer la configuration Ollama
    print("\nğŸ”§ 3. Application de la configuration forcÃ©e:")
    
    # Configuration forcÃ©e
    config_forcee = {
        "llm_provider": "ollama",
        "ollama": {
            "model": "gpt-oss:20b",
            "base_url": "http://localhost:11434",
            "timeout": 120
        },
        "openai": config.get("openai", {}),
        "anthropic": config.get("anthropic", {}),
        "gemini": config.get("gemini", {}),
        "mistral": config.get("mistral", {}),
        "openrouter": config.get("openrouter", {})
    }
    
    print("   ğŸ“ Configuration appliquÃ©e:")
    print(f"      - Provider LLM: {config_forcee['llm_provider']}")
    print(f"      - ModÃ¨le Ollama: {config_forcee['ollama']['model']}")
    print(f"      - URL: {config_forcee['ollama']['base_url']}")
    print(f"      - Timeout: {config_forcee['ollama']['timeout']}s")
    
    # 4. Sauvegarder la nouvelle configuration
    print("\nğŸ’¾ 4. Sauvegarde de la nouvelle configuration:")
    
    try:
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config_forcee, f, indent=2, ensure_ascii=False)
        print(f"   âœ… Configuration sauvegardÃ©e dans {config_file}")
    except Exception as e:
        print(f"   âŒ Erreur sauvegarde: {e}")
        return False
    
    # 5. VÃ©rifier que la configuration est bien appliquÃ©e
    print("\nğŸ” 5. VÃ©rification de la configuration appliquÃ©e:")
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config_verif = json.load(f)
        
        if (config_verif.get('llm_provider') == 'ollama' and 
            config_verif.get('ollama', {}).get('model') == 'gpt-oss:20b'):
            print("   âœ… Configuration vÃ©rifiÃ©e avec succÃ¨s!")
            print("   ğŸ¯ Ollama est configurÃ© pour utiliser gpt-oss:20b")
        else:
            print("   âŒ Configuration incorrecte aprÃ¨s sauvegarde")
            return False
            
    except Exception as e:
        print(f"   âŒ Erreur vÃ©rification: {e}")
        return False
    
    # 6. Instructions de test
    print("\nğŸ“‹ 6. INSTRUCTIONS DE TEST:")
    
    print("   ğŸš€ Maintenant testez votre application:")
    print("   1. ğŸ“± Ouvrir MatelasApp")
    print("   2. ğŸ”§ VÃ©rifier dans 'Gestion des clÃ©s API' que Ollama est sÃ©lectionnÃ©")
    print("   3. ğŸ“„ SÃ©lectionner votre PDF COSTENOBLE")
    print("   4. âœ… Cocher 'Utiliser l'enrichissement LLM'")
    print("   5. ğŸš€ Cliquer sur 'Traiter les fichiers'")
    
    print("\n   ğŸ” VÃ©rifications Ã  faire:")
    print("   - Dans les logs: 'ollama run gpt-oss:20b' (pas mistral:latest)")
    print("   - Parsing JSON rÃ©ussi")
    print("   - Dimensions extraites correctement")
    print("   - Fourgon dÃ©tectÃ© et rempli")
    print("   - Fichiers Excel gÃ©nÃ©rÃ©s avec succÃ¨s")
    
    # 7. Test rapide de la configuration
    print("\nğŸ§ª 7. Test rapide de la configuration:")
    
    try:
        import subprocess
        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
        
        if result.returncode == 0:
            if 'gpt-oss:20b' in result.stdout:
                print("   âœ… gpt-oss:20b est disponible sur votre systÃ¨me")
            else:
                print("   âš ï¸ gpt-oss:20b n'est pas dans la liste des modÃ¨les")
                print("   ğŸ’¡ VÃ©rifiez que le modÃ¨le est bien installÃ©")
        else:
            print("   âŒ Impossible de vÃ©rifier les modÃ¨les Ollama")
            
    except Exception as e:
        print(f"   âŒ Erreur lors de la vÃ©rification des modÃ¨les: {e}")
    
    return True

def instructions_depannage():
    """Instructions de dÃ©pannage si le problÃ¨me persiste"""
    
    print("\nğŸ”§ INSTRUCTIONS DE DÃ‰PANNAGE:")
    
    print("   Si le problÃ¨me persiste avec mistral:latest:")
    print("   1. ğŸ” VÃ©rifier que gpt-oss:20b est bien installÃ©:")
    print("      ollama list | grep gpt-oss")
    print("   2. ğŸš€ DÃ©marrer le modÃ¨le gpt-oss:20b:")
    print("      ollama run gpt-oss:20b")
    print("   3. ğŸ”„ RedÃ©marrer l'application MatelasApp")
    print("   4. ğŸ“ VÃ©rifier que la configuration est bien sauvegardÃ©e")
    
    print("\n   ğŸ“Š VÃ©rification des logs:")
    print("   - Chercher 'ollama run gpt-oss:20b' dans debug_llm.log")
    print("   - Ã‰viter 'ollama run mistral:latest'")
    print("   - S'assurer que le parsing JSON rÃ©ussit")

if __name__ == "__main__":
    print("ğŸ¯ FORÃ‡AGE DE LA CONFIGURATION OLLAMA")
    print("Ce script va forcer l'utilisation de gpt-oss:20b")
    
    # Application de la configuration forcÃ©e
    success = forcer_configuration_gpt_oss()
    
    # Instructions de dÃ©pannage
    instructions_depannage()
    
    if success:
        print("\nğŸ‰ RÃ‰SUMÃ‰:")
        print("âœ… Configuration Ollama forcÃ©e avec gpt-oss:20b")
        print("âœ… Sauvegarde de l'ancienne configuration crÃ©Ã©e")
        print("ğŸš€ PrÃªt pour tester avec votre PDF COSTENOBLE")
        print("ğŸ” VÃ©rifiez que gpt-oss:20b est utilisÃ© au lieu de mistral:latest")
    else:
        print("\nâŒ ProblÃ¨me lors de la configuration forcÃ©e")
        print("ğŸ”§ VÃ©rifiez les erreurs et rÃ©essayez")
    
    print("\n=== FIN DU FORÃ‡AGE DE CONFIGURATION ===")

